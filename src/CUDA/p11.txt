核函数外部的并行：
1.核函数计算与数据传输之间的并行
2.主机计算与数据传输之间的并行
3.不同的数据传输之间的并行
4.核函数计算与主机计算之间的并行
5.不同核函数之间的并行

创建一个CUDA流
cudaError_t cudaStreamDestory(cudaStream_t *);

cudaStream_t stream_1;
cudaStreamCreate(&stream_1); // 注意要传流的地址
cudaStreamDestroy(stream_1);
错误方法：
	cudaStream_t *stream_1;
	cudaStreamCreate(stream_1); // 注意要传流的地址
	cudaStreamDestroy(*stream_1);

等待流结束
cudaError_t cudaStreamSynchronize(cudaStream_t stream);
检查流是否完成，完成返回cudaSuccess，否则返回cudaErrorNotReady
cudaError_t cudaStreamQuery(cudaStream_t stream);

同一个 CUDA 流中的 CUDA 操作在设备中是顺序执行的，
故同一个 CUDA 流中的核函数也必须在设备中顺序执行
但主机发出一个核函数调用的命令之后都立刻获得程序控制权

调用核函数的三种方式
my_kernel<<<N_grid, N_block>>>(函数参数);
my_kernel<<<N_grid, N_block, N_shared>>>(函数参数);
my_kernel<<<N_grid, N_block, N_shared, stream_id>>>(函数参数);

如果要使用非默认流，不可以省去参数N_shared, 如果不需要共享内存，可以传0
my_kernel<<<N_grid, N_block, 0, stream_id>>>(函数参数); // 正确
不能用如下调用方式：
my_kernel<<<N_grid, N_block, stream_id>>>(函数参数); // 错误

单个GPU中能够并发执行的核函数个数的上限：
在计算能力为 
3.0、3.2、3.5、3.7、5.0、5.2、5.3、6.0、6.1、6.2、7.0 和 7.5 的 GPU 中，该上限的值分别为 
16、  4、  32、 32、 32、32、 16、128、32、16、128 和 128

异步传输由GPU中的DMA（Direct Memory Access直接内存访问）直接实现
cudaError_t cudaMemcpyAsync
(
	void *dst,
	const void *src,
	size_t count;
	enum cudaMemcpyKind kind,
	cudaStream_t stream
);
cudaMemcpyAsync之比cudaMemcpy多一个参数 cudaStream_t
关于enum，C++的派生类型，可以通过一些操作自动赋值
https://www.runoob.com/w3cnote/cpp-enum-intro.html